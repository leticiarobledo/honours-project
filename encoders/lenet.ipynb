{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s1928563/programs/miniconda3/envs/adbench/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1,\n",
    "            out_channels=6,\n",
    "            kernel_size=4,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=6,\n",
    "            out_channels=16,\n",
    "            kernel_size=4,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=16,\n",
    "            out_channels=144,\n",
    "            kernel_size=4,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "        )\n",
    "        self.linear1 = nn.Linear(144, 84)\n",
    "        self.linear2 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.relu(\n",
    "            self.conv3(x)\n",
    "        )  # num_examples x 120 x 1 x 1 --> num_examples x 120\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 20\n",
    "\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn  # All neural network modules\n",
    "from tqdm import tqdm  # For nice progress bar!\n",
    "model = LeNet()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got test\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import get_datasets_validation\n",
    "train_loader, val_loader, test_loader = get_datasets_validation(\"dataset\", 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on training & test to see how good our model\n",
    "def check_accuracy(loader, model):\n",
    "    \"\"\"\n",
    "    Check accuracy of our trained model given a loader and a model\n",
    "    Parameters:\n",
    "        loader: torch.utils.data.DataLoader\n",
    "            A loader for the dataset you want to check accuracy on\n",
    "        model: nn.Module\n",
    "            The model you want to check accuracy on\n",
    "    Returns:\n",
    "        acc: float\n",
    "            The accuracy of the model on the dataset given by the loader\n",
    "    \"\"\"\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    # We don't need to keep track of gradients here so we wrap it in torch.no_grad()\n",
    "    with torch.no_grad():\n",
    "        # Loop through the data\n",
    "        for x, y in loader:\n",
    "            # Move data to device\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            # Get to correct shape\n",
    "            # x = x.reshape(x.shape[0], -1)\n",
    "            x = x.float()\n",
    "            # Forward pass\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            # Check how many we got correct\n",
    "            num_correct += (predictions == y).sum()\n",
    "            # Keep track of number of samples\n",
    "            num_samples += predictions.size(0)\n",
    "    model.train()\n",
    "    return num_correct / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6227/6227 [00:33<00:00, 185.89it/s]\n",
      "100%|██████████| 6227/6227 [00:31<00:00, 198.66it/s]\n",
      "100%|██████████| 6227/6227 [00:29<00:00, 211.32it/s]\n",
      "100%|██████████| 6227/6227 [00:30<00:00, 207.36it/s]\n",
      "100%|██████████| 6227/6227 [00:29<00:00, 210.84it/s]\n",
      "100%|██████████| 6227/6227 [00:29<00:00, 211.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 5\n",
      "Loss: tensor(0.0052, grad_fn=<NllLossBackward0>)\n",
      "Accuracy on training set: 96.91\n",
      "Accuracy on validation set: 95.75\n",
      "Accuracy on test set: 90.28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6227/6227 [00:31<00:00, 198.32it/s]\n",
      "100%|██████████| 6227/6227 [00:31<00:00, 196.74it/s]\n",
      "100%|██████████| 6227/6227 [00:32<00:00, 192.66it/s]\n",
      "100%|██████████| 6227/6227 [00:33<00:00, 183.77it/s]\n",
      "100%|██████████| 6227/6227 [00:37<00:00, 166.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 10\n",
      "Loss: tensor(0.1539, grad_fn=<NllLossBackward0>)\n",
      "Accuracy on training set: 97.93\n",
      "Accuracy on validation set: 96.21\n",
      "Accuracy on test set: 90.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6227/6227 [00:39<00:00, 156.84it/s]\n",
      "100%|██████████| 6227/6227 [00:42<00:00, 146.68it/s]\n",
      "100%|██████████| 6227/6227 [00:40<00:00, 154.20it/s]\n",
      "100%|██████████| 6227/6227 [00:41<00:00, 150.39it/s]\n",
      "100%|██████████| 6227/6227 [00:41<00:00, 149.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 15\n",
      "Loss: tensor(0.1640, grad_fn=<NllLossBackward0>)\n",
      "Accuracy on training set: 98.06\n",
      "Accuracy on validation set: 96.01\n",
      "Accuracy on test set: 90.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6227/6227 [00:41<00:00, 148.71it/s]\n",
      "100%|██████████| 6227/6227 [00:41<00:00, 151.03it/s]\n",
      "100%|██████████| 6227/6227 [00:41<00:00, 151.43it/s]\n",
      "100%|██████████| 6227/6227 [00:41<00:00, 150.09it/s]\n",
      "100%|██████████| 6227/6227 [00:42<00:00, 146.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 20\n",
      "Loss: tensor(0.0609, grad_fn=<NllLossBackward0>)\n",
      "Accuracy on training set: 98.72\n",
      "Accuracy on validation set: 96.17\n",
      "Accuracy on test set: 90.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6227/6227 [00:40<00:00, 152.47it/s]\n",
      "100%|██████████| 6227/6227 [00:41<00:00, 150.97it/s]\n",
      "100%|██████████| 6227/6227 [00:42<00:00, 146.52it/s]\n",
      "100%|██████████| 6227/6227 [00:41<00:00, 149.86it/s]\n",
      "100%|██████████| 6227/6227 [00:42<00:00, 144.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 25\n",
      "Loss: tensor(0.0044, grad_fn=<NllLossBackward0>)\n",
      "Accuracy on training set: 98.62\n",
      "Accuracy on validation set: 95.89\n",
      "Accuracy on test set: 90.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6227/6227 [00:39<00:00, 157.55it/s]\n",
      "100%|██████████| 6227/6227 [00:41<00:00, 150.22it/s]\n",
      "100%|██████████| 6227/6227 [00:42<00:00, 148.03it/s]\n",
      "100%|██████████| 6227/6227 [00:43<00:00, 142.92it/s]\n",
      "100%|██████████| 6227/6227 [00:43<00:00, 143.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 30\n",
      "Loss: tensor(0.0052, grad_fn=<NllLossBackward0>)\n",
      "Accuracy on training set: 98.84\n",
      "Accuracy on validation set: 95.85\n",
      "Accuracy on test set: 89.32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6227/6227 [00:42<00:00, 146.30it/s]\n",
      "100%|██████████| 6227/6227 [00:42<00:00, 144.96it/s]\n",
      "100%|██████████| 6227/6227 [00:44<00:00, 139.34it/s]\n",
      "100%|██████████| 6227/6227 [00:44<00:00, 138.38it/s]\n",
      "100%|██████████| 6227/6227 [00:43<00:00, 142.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 35\n",
      "Loss: tensor(0.0071, grad_fn=<NllLossBackward0>)\n",
      "Accuracy on training set: 98.90\n",
      "Accuracy on validation set: 95.99\n",
      "Accuracy on test set: 89.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6227/6227 [00:43<00:00, 143.18it/s]\n",
      "100%|██████████| 6227/6227 [00:44<00:00, 139.19it/s]\n",
      "100%|██████████| 6227/6227 [00:45<00:00, 135.65it/s]\n",
      "100%|██████████| 6227/6227 [00:49<00:00, 125.94it/s]\n",
      "100%|██████████| 6227/6227 [00:45<00:00, 137.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 40\n",
      "Loss: tensor(0.2519, grad_fn=<NllLossBackward0>)\n",
      "Accuracy on training set: 99.05\n",
      "Accuracy on validation set: 95.81\n",
      "Accuracy on test set: 89.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6227/6227 [00:46<00:00, 132.63it/s]\n",
      "100%|██████████| 6227/6227 [00:46<00:00, 134.04it/s]\n",
      "100%|██████████| 6227/6227 [00:44<00:00, 139.32it/s]\n",
      "100%|██████████| 6227/6227 [00:46<00:00, 133.25it/s]\n",
      "100%|██████████| 6227/6227 [00:44<00:00, 139.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 45\n",
      "Loss: tensor(0.0019, grad_fn=<NllLossBackward0>)\n",
      "Accuracy on training set: 99.00\n",
      "Accuracy on validation set: 95.75\n",
      "Accuracy on test set: 89.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6227/6227 [00:45<00:00, 135.43it/s]\n",
      "100%|██████████| 6227/6227 [00:46<00:00, 135.37it/s]\n",
      "100%|██████████| 6227/6227 [00:45<00:00, 136.97it/s]\n",
      "100%|██████████| 6227/6227 [00:44<00:00, 138.51it/s]\n",
      "100%|██████████| 6227/6227 [00:46<00:00, 135.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 50\n",
      "Loss: tensor(0.0007, grad_fn=<NllLossBackward0>)\n",
      "Accuracy on training set: 98.97\n",
      "Accuracy on validation set: 95.71\n",
      "Accuracy on test set: 89.42\n"
     ]
    }
   ],
   "source": [
    "# Train Network\n",
    "\n",
    "# Define some variables to keep track of the best model and validation accuracy\n",
    "best_model = None\n",
    "best_val_acc = 0.0\n",
    "path = \"lenet/lenet_50_epochs_64_batch_2.txt\"\n",
    "\n",
    "with open(path, \"w\") as f:\n",
    "    for epoch in range(51):\n",
    "        \n",
    "        for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "            # Get data to cuda if possible\n",
    "            data = data.to(device=device)\n",
    "            # print(data.shape)\n",
    "            targets = targets.to(device=device)\n",
    "            # print(targets.shape)\n",
    "\n",
    "            # Get to correct shape\n",
    "            # data = data.reshape(data.shape[0], -1)\n",
    "            # print(data.shape)\n",
    "            data = data.float()\n",
    "            # Forward\n",
    "            scores = model(data)\n",
    "            loss = criterion(scores, targets)\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            # Gradient descent or adam step\n",
    "            optimizer.step()\n",
    "        \n",
    "        if epoch % 5 == 0 and epoch != 0:\n",
    "            val_acc = check_accuracy(val_loader, model)\n",
    "            train_acc = check_accuracy(train_loader, model)\n",
    "            test_acc = check_accuracy(test_loader, model)\n",
    "            # If the current model has a better validation accuracy, save it\n",
    "            if val_acc > best_val_acc:\n",
    "                best_model = model.state_dict()\n",
    "                best_val_acc = val_acc\n",
    "\n",
    "            # Check accuracy on training & test to see how good our model\n",
    "            print(\"EPOCH: \" + str(epoch))\n",
    "            print(\"Loss: \" + str(loss))\n",
    "            print(f\"Accuracy on training set: {train_acc*100:.2f}\")\n",
    "            print(f\"Accuracy on validation set: {val_acc*100:.2f}\")\n",
    "            print(f\"Accuracy on test set: {test_acc*100:.2f}\")\n",
    "            f.write(\"EPOCH \" + str(epoch) + \n",
    "                    \", loss:\"+str(loss) +\n",
    "                    \", train_acc:\" + str(train_acc) + \n",
    "                    \", val_acc:\" + str(val_acc) +\n",
    "                    \", test_acc:\" + str(test_acc) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9621)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Saving checkpoint\n"
     ]
    }
   ],
   "source": [
    "def save_checkpoint(state, filename):\n",
    "    name = filename + \".pth.tar\"\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    torch.save(state, name)\n",
    "\n",
    "# save model\n",
    "checkpoint = {\"state_dict\": best_model, \"optimizer\": optimizer.state_dict()}\n",
    "# Try save checkpoint\n",
    "save_checkpoint(checkpoint, filename=\"lenet_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inference time\n",
    "import torch.nn as nn\n",
    "inf = LeNet()\n",
    "inf.linear1 = nn.Identity()\n",
    "inf.linear2 = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (relu): ReLU()\n",
       "  (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (conv3): Conv2d(16, 144, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (linear1): Identity()\n",
       "  (linear2): Identity()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'lenet_50_epochs_64_batch.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1958264/4028404573.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#### PLOT LENET BEST MODEL IDENTIFICATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"lenet_50_epochs_64_batch.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# list containing lines of file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'lenet_50_epochs_64_batch.txt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#### PLOT LENET BEST MODEL IDENTIFICATION\n",
    "path = \"lenet_50_epochs_64_batch.txt\"\n",
    "epochs = dict()\n",
    "with open(path) as f:\n",
    "    lines = f.readlines() # list containing lines of file\n",
    "    epochs = []\n",
    "    loss = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    test_acc = []\n",
    "    for l in lines:\n",
    "        split_l = l.split(',')\n",
    "        epoch = split_l[0].split(\" \")[-1]\n",
    "        if epoch not in epochs.keys():\n",
    "            epochs[epoch] = [\"train\": [], \"test\": [], \"val\": []]\n",
    "\n",
    "    for line in lines:\n",
    "        split_l = l.split(',')\n",
    "        epoch = split_l[0].split(\" \")[-1]\n",
    "        if epoch in epochs:\n",
    "            acc = float(split_l[3].split(\":\")[1][7:-1])\n",
    "            val = float(split_l[4].split(\":\")[1][7:-1])\n",
    "            test = float(split_l[5].split(\":\")[1][7:-2])\n",
    "            epochs[epoch][\"train\"].append(acc) \n",
    "            epochs[epoch][\"test\"].append(test) \n",
    "            epochs[epoch][\"val\"].append(val) \n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "default_x_ticks = range(len(epochs))\n",
    "axs.set_xticks(default_x_ticks, epochs)\n",
    "\n",
    "axs.plot(default_x_ticks,test_acc, label=\"Test set\")\n",
    "axs.plot(default_x_ticks,val_acc, label=\"Validation set\")\n",
    "axs.plot(default_x_ticks,train_acc, label=\"Train set\")\n",
    "\n",
    "axs.set_title(\"LeNet-5 Performance on All Datasets\")\n",
    "axs.set_ylabel(\"Score\")\n",
    "axs.set_xlabel(\"Epochs\")\n",
    "\n",
    "axs.legend()\n",
    "plt.savefig(\"lenet.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79e16aa75c14fe4c8ae63c34bb3e5f0b797becc9118297689cd67b6f19ec46a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
